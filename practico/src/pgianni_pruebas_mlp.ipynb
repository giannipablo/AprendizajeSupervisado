{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data_fname, test_data_fname):\n",
    "    df_train = pd.read_csv(train_data_fname)\n",
    "    df_train['is_train_set'] = 1\n",
    "    df_test = pd.read_csv(test_data_fname)\n",
    "    df_test['is_train_set'] = 0\n",
    "\n",
    "    # we  get the TripType for the train set. To do that, we group by VisitNumber and\n",
    "    # then we get the max (or min or avg)\n",
    "    y = df_train.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).max().TripType\n",
    "\n",
    "    # we remove the TripType now, and concat training and testing data\n",
    "    # the concat is done so that we have the same columns for both datasets\n",
    "    # after one-hot encoding\n",
    "    df_train = df_train.drop(\"TripType\", axis=1)\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    \n",
    "    # the next three operations are the ones we have just presented in the previous lines\n",
    "    \n",
    "    # drop the columns we won't use (it may be good to use them somehow)\n",
    "    df = df.drop([\"Upc\", \"FinelineNumber\"], axis=1)\n",
    "\n",
    "    # one-hot encoding for the DepartmentDescription\n",
    "    df = pd.get_dummies(df, columns=[\"DepartmentDescription\"], dummy_na=True)\n",
    "\n",
    "    # now we add the groupby values\n",
    "    df = df.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).sum()\n",
    "    \n",
    "    # finally, we do one-hot encoding for the Weekday\n",
    "    df = pd.get_dummies(df, columns=[\"Weekday\"], dummy_na=True)\n",
    "\n",
    "    # get train and test back\n",
    "    df_train = df[df.is_train_set != 0]\n",
    "    df_test = df[df.is_train_set == 0]\n",
    "    \n",
    "    X = df_train.drop([\"is_train_set\"], axis=1)\n",
    "    yy = None\n",
    "    XX = df_test.drop([\"is_train_set\"], axis=1)\n",
    "\n",
    "    return X, y, XX, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, XX, yy = transform_data(\"../data/train.csv\", \"../data/test.csv\")\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalizaci√≥n\n",
    "SS = StandardScaler()\n",
    "SS.fit(X_train)\n",
    "X_train = SS.transform(X_train)\n",
    "X_valid = SS.transform(X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67029, 79)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:  1.7min remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  2.7min finished\n"
     ]
    }
   ],
   "source": [
    "mlp_model = clf = MLPClassifier(random_state=42)\n",
    "\n",
    "param_grid_mlp = [\n",
    "    {'solver': ['adam'],\n",
    "     'alpha': [1e-5],\n",
    "     'activation': ['relu', 'logistic'],\n",
    "     'learning_rate': ['adaptive'],\n",
    "     'hidden_layer_sizes': [79]\n",
    "    }\n",
    "]\n",
    "\n",
    "gscv_mlp = GridSearchCV(mlp_model, param_grid_mlp, cv=3, scoring=['accuracy'], refit=False, n_jobs=-1, verbose=4)\n",
    "gscv_mlp.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.689252</td>\n",
       "      <td>0.492558</td>\n",
       "      <td>0.097417</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(79, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'hidden...</td>\n",
       "      <td>0.522059</td>\n",
       "      <td>0.525384</td>\n",
       "      <td>0.525959</td>\n",
       "      <td>0.524467</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.774154</td>\n",
       "      <td>16.672646</td>\n",
       "      <td>0.071928</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>logistic</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(79, 2)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 1e-05, 'hi...</td>\n",
       "      <td>0.472442</td>\n",
       "      <td>0.447826</td>\n",
       "      <td>0.463683</td>\n",
       "      <td>0.461317</td>\n",
       "      <td>0.010188</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      98.689252      0.492558         0.097417        0.006723   \n",
       "1      73.774154     16.672646         0.071928        0.024390   \n",
       "\n",
       "  param_activation param_alpha param_hidden_layer_sizes param_learning_rate  \\\n",
       "0             relu       1e-05                  (79, 2)            adaptive   \n",
       "1         logistic       1e-05                  (79, 2)            adaptive   \n",
       "\n",
       "  param_solver                                             params  \\\n",
       "0         adam  {'activation': 'relu', 'alpha': 1e-05, 'hidden...   \n",
       "1         adam  {'activation': 'logistic', 'alpha': 1e-05, 'hi...   \n",
       "\n",
       "   split0_test_accuracy  split1_test_accuracy  split2_test_accuracy  \\\n",
       "0              0.522059              0.525384              0.525959   \n",
       "1              0.472442              0.447826              0.463683   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \n",
       "0            0.524467           0.001719                   1  \n",
       "1            0.461317           0.010188                   2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_mlp_res = pd.DataFrame(gscv_mlp.cv_results_)\n",
    "gscv_mlp_res.sort_values(by='rank_test_accuracy') #.to_csv('./prueba3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = gscv_mlp_res[gscv_mlp_res.rank_test_accuracy==1]\n",
    "best.to_csv('./pg_submission_best_config_mlp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pgianni/venv/diplo/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7516624040920716, 0.6879506688547417)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(**best.params.values[0], random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = mlp_model.predict(X_train)\n",
    "y_pred_valid = mlp_model.predict(X_valid)\n",
    "\n",
    "accuracy_score(y_train, y_pred_train),accuracy_score(y_valid, y_pred_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXn = SS.transform(XX)\n",
    "y2send = mlp_model.predict(XXn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.VisitNumber, y2send)), columns=[\"VisitNumber\", \"TripType\"])\n",
    "submission.to_csv(\"./pg_submission_mlp.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('diplo': venv)",
   "language": "python",
   "name": "python37664bitdiplovenvc8f1cc3d26344ed08febef30f9915ee6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
